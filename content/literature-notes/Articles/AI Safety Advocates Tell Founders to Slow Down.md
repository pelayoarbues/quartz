---
author: [[Amanda Silberling]]
title: "AI Safety Advocates Tell Founders to Slow Down"
date: 2024-11-05
tags: 
- articles
- literature-note
---
![rw-book-cover](https://techcrunch.com/wp-content/uploads/2024/02/connectwise-flaw-huntress-security.jpg?resize=1200,800)

## Metadata
- Author: [[Amanda Silberling]]
- Full Title: AI Safety Advocates Tell Founders to Slow Down
- URL: https://techcrunch.com/2024/11/05/ai-safety-advocates-tell-founders-to-slow-down/?utm_source=dlvr.it&utm_medium=bluesky

## Highlights
- “Move cautiously and red-team things” is sadly not as catchy as “move fast and break things.” But three AI safety advocates made it clear to startup founders that going too fast can lead to ethical issues in the long run. ([View Highlight](https://read.readwise.io/read/01jbz55m7pppy3sdmqsr7z1ad9))
- “We are at an inflection point where there are tons of resources being moved into this space,” said Sarah Myers West, co-executive director of the AI Now Institute, onstage at [TechCrunch Disrupt 2024](https://techcrunch.com/storyline/techcrunch-disrupt-2024-day-3-the-future-of-wordpress-perplexity-ai-and-colin-kaepernick/). “I’m really worried that right now there’s just such a rush to sort of push product out onto the world, without thinking about that legacy question of what is the world that we really want to live in, and in what ways is the technology that’s being produced acting in service of that world or actively harming it.” ([View Highlight](https://read.readwise.io/read/01jbz56b40yh9y1ct7bw982zdm))
- The conversation comes at a moment when the issue of AI safety feels more pressing than ever. In October, the family of a child who died by suicide [sued chatbot company Character.AI](https://techcrunch.com/2024/10/23/lawsuit-blames-character-ai-in-death-of-14-year-old-boy/) for its alleged role in the child’s death. ([View Highlight](https://read.readwise.io/read/01jbz56g3dfnjj12q76180mq4r))
- “We are building something that has a lot of power and the ability to really, really impact people’s lives,” said Jingna Zhang, founder of artist-forward social platform [Cara](https://techcrunch.com/2024/06/06/a-social-app-for-creatives-cara-grew-from-40k-to-650k-users-in-a-week-because-artists-are-fed-up-with-metas-ai-policies/). “When you talk about something like Character.AI, that emotionally really engages with somebody, it makes sense that I think there should be guardrails around how the product is built.” ([View Highlight](https://read.readwise.io/read/01jbz56z1xk7rva2r0vchzzw9p))
- Zhang’s platform Cara took off after Meta made it clear that it could use any user’s public posts to train its AI. For artists like Zhang herself, this policy is a slap in the face. Artists need to post their work online to build a following and secure potential clients, but by doing that, their work could be used to shape the very AI models that could one day put them out of work. ([View Highlight](https://read.readwise.io/read/01jbz576mweh1cvhracmaxp6vc))
- “Copyright is what protects us and allows us to make a living,” Zhang said. If artwork is available online, that doesn’t mean it’s free, per se — digital news publications, for example, have to license images from photographers in order to use them. “When generative AI started becoming much more mainstream, what we are seeing is that it does not work with what we are typically used to, that’s been established in law. And if they wanted to use our work, they should be licensing it.” ([View Highlight](https://read.readwise.io/read/01jbz57j8h97r3tfenttn6js0n))
- Artists could also be impacted by products like ElevenLabs, an AI voice cloning company that’s worth [over a billion dollars](https://techcrunch.com/2024/01/22/voice-cloning-startup-elevenlabs-lands-80m-achieves-unicorn-status/). As head of safety at ElevenLabs, it’s up to Aleksandra Pedraszewska to make sure that the company’s sophisticated technology isn’t co-opted for nonconsensual deepfakes, among other things. ([View Highlight](https://read.readwise.io/read/01jbz58626e0rfngar6s8x1tt4))
- “I think red-teaming models, understanding undesirable behaviors, and unintended consequences of any new launch that a generative AI company does is again becoming [a top priority],” she said. “ElevenLabs has 33 million users today. This is a massive community that gets impacted by any change that we make in our product.” ([View Highlight](https://read.readwise.io/read/01jbz587hmm1mjken1k52xcz7v))
- “We cannot just operate between two extremes, one being entirely anti-AI and anti-GenAI, and then another one, effectively trying to persuade zero regulation of the space. I think that we do need to meet in the middle when it comes to regulation,” she said. ([View Highlight](https://read.readwise.io/read/01jbz58hn452pttqwkvx7kb8d0))
