---
author: [[Gradio]]
title: "ğŸ¤© ğŒğ¢ğ§ğ¢-ğ†ğğ¦ğ¢ğ§ğ¢ : A new framework that can enhance Vision..."
date: 2024-04-26
tags: 
- tweets
- literature-note
---
![rw-book-cover](https://pbs.twimg.com/profile_images/1717418871165161472/qdZZBtz2_normal.jpg)

## Metadata
- Author: [[Gradio]]
- Full Title: ğŸ¤© ğŒğ¢ğ§ğ¢-ğ†ğğ¦ğ¢ğ§ğ¢ : A new framework that can enhance Vision...
- URL: https://twitter.com/Gradio/status/1783140570610733192

## Highlights
- ğŸ¤© ğŒğ¢ğ§ğ¢-ğ†ğğ¦ğ¢ğ§ğ¢ : A new framework that can enhance Vision Language Models to bridge gap between OS VLMs and models like GPT4 ([View Highlight](https://read.readwise.io/read/01hwct159c67drdtkd1kcccnam))
- Proposes dual vision encoders for high-res refinement without increasing visual tokens 
  ğŸ”§High-quality datasets on ğŸ¤—Hub 
  ğŸ”§VLM-guided image understanding & generation ([View Highlight](https://read.readwise.io/read/01hwct1akyw4ay10dg35jsn1vq))
- ğŸ’ª Mini-Gemini supports dense and MoE Large Language Models (LLMs) from 2B to 34B. 
  ğŸ“Š Achieves leading performance in zero-shot benchmarks, surpassing developed private models. ([View Highlight](https://read.readwise.io/read/01hwct1eewa48njahyj6mvj1fh))
