---
author: [[@jrysana on Twitter]]
title: "Introducing Inversion, O..."
date: 2024-03-18
tags: 
- tweets
- literature-note
---
![rw-book-cover](https://pbs.twimg.com/profile_images/1757242446679789569/s3YijRaf.jpg)

## Metadata
- Author: [[@jrysana on Twitter]]
- Full Title: Introducing Inversion, O...
- URL: https://twitter.com/jrysana/status/1769786911030186111

## Highlights
- Introducing Inversion, our family of structured LLMs.
  Our first generation models excel in structured tasks, offering unmatched speed, latency, reliability, and efficiency, with the most comprehensive typed JSON output support available anywhere.
  https://t.co/208O8G4KFz <video controls><source src="https://video.twimg.com/ext_tw_video/1769782018928152576/pu/pl/olIo_JL49EoykeyO.m3u8?tag=12&container=cmaf" type="application/x-mpegURL"><source src="https://video.twimg.com/ext_tw_video/1769782018928152576/pu/vid/avc1/480x270/TobTHAmxdgVRF_ej.mp4?tag=12" type="video/mp4"><source src="https://video.twimg.com/ext_tw_video/1769782018928152576/pu/vid/avc1/640x360/i9qR8-rkiC8I37MH.mp4?tag=12" type="video/mp4"><source src="https://video.twimg.com/ext_tw_video/1769782018928152576/pu/vid/avc1/1280x720/Y5Uxfw6lsvg2PL2l.mp4?tag=12" type="video/mp4">Your browser does not support the video tag.</video> ([View Tweet](https://twitter.com/jrysana/status/1769786911030186111))
- ~100x faster
  Inversion uses accelerated structured inference to generate reliable outputs at up to about 50,000 tokens per second, and typically much faster than even its unstructured peers on similar tasks. 
  ![](https://pbs.twimg.com/media/GI-JYKQXoAAwdD2.jpg) ([View Tweet](https://twitter.com/jrysana/status/1769786913123123610))
- Reliable & smart
  Inversion performs remarkably well on structured tasks like action/function-calling, typed extraction, and synthetic data generation - often surpassing models 10x or 100x larger in size. 
  ![](https://pbs.twimg.com/media/GI-J3PSXAAA9n36.png) ([View Tweet](https://twitter.com/jrysana/status/1769786915279057268))
- ~10,000x less overhead
  Inversion has the fastest system in the world for deeply typed structured generation with LLMs, with the lowest compilation time and runtime overhead we've seen anywhere by far. 
  ![](https://pbs.twimg.com/media/GI-KTthXYAALhXd.jpg) ([View Tweet](https://twitter.com/jrysana/status/1769786917611053463))
- ~0% type error rate
  By enforcing structure deeply during generation, Inversion achieves a perfect type reliability rate across hundreds of typed output tests. 
  ![](https://pbs.twimg.com/media/GI-KjjEW4AAdzTR.jpg) ([View Tweet](https://twitter.com/jrysana/status/1769786919708229636))
- Lightning fast
  Inversion starts responding in the blink of an eye, and can often generate an entire response with hundreds of tokens in the input and output within <100ms. 
  ![](https://pbs.twimg.com/media/GI-KqBVWAAAfUDH.jpg) ([View Tweet](https://twitter.com/jrysana/status/1769786921968918588))
- Feel the speed!
  https://t.co/J8LBwEedPT ([View Tweet](https://twitter.com/jrysana/status/1769786923680202957))
- We're working on bringing Inversion to developers everywhere with the best possible DX through SDKs and a reliable platform at scale.
  We're also working on the next generation of Inversion models, targeting even faster and especially smarter responses for taking useful actions. ([View Tweet](https://twitter.com/jrysana/status/1769786925387309553))
- If you're interested in what we're building, please reach out - and take a look at the full post on our site:
  https://t.co/J7yq64IAlz ([View Tweet](https://twitter.com/jrysana/status/1769787631317991595))
