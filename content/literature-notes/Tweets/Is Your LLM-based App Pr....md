---
author: [[@ItakGol on Twitter]]
title: "Is Your LLM-based App Pr..."
tags: 
- tweets
- literature-note
---
# Is Your LLM-based App Pr...

![rw-book-cover](https://pbs.twimg.com/profile_images/1607731843364753413/p8Rak9Qx.jpg)

## Metadata
- Author: [[@ItakGol on Twitter]]
- Full Title: Is Your LLM-based App Pr...
- Category: #tweets
- URL: https://twitter.com/ItakGol/status/1666566834869420035

## Highlights
- Is your LLM-based App protected against Prompt Injection and Hijacking? 🥷🦹‍♂️
  I bet it doesn't!
  Witness firsthand the potential impact as I demonstrate the Hacking/Exploitation of this Demo App>>>
  🧵 1/12 
  ![](https://pbs.twimg.com/media/FyDOg2yXwAI3RWJ.png) ([View Tweet](https://twitter.com/ItakGol/status/1666566834869420035))
- Let's consider a very simple app called FitGPT. 
  Given some basic information, it will provide the client with some fitness advice. Below you can watch how it works in the happy flow. Nice and simple.
  But now let's see what it looks like under the hood>>>
  🧵 2/8 
  ![](https://pbs.twimg.com/media/FyDP5r_WAAI_EV6.jpg) ([View Tweet](https://twitter.com/ItakGol/status/1666566837809577986))
- This App uses simple template strings to create a prompt.
  It collects the user's inputs for sex/height/weight/comments and then plugs them into a final prompt. 
  Then, we call our LLM with this prompt.
  Pretty simple stuff, 
  but it can be really Dangerous.
  🧵 3/8 
  ![](https://pbs.twimg.com/media/FyDQtc9XsAEZOJy.jpg) ([View Tweet](https://twitter.com/ItakGol/status/1666566840540119040))
- Prompt injection and beyond! 🌠
  By instructing the AI to 'ignore all previous instructions,' the hacker gains full control over the AI.
  A malicious actor can now make your app say absurd things, capture screenshots and share them with the all world.
  🧵 4/8 
  ![](https://pbs.twimg.com/media/FyDReh3XoAINVK7.png) ([View Tweet](https://twitter.com/ItakGol/status/1666566843031605249))
- Your business's reputation is at risk and a lawsuit may be imminent for this {k}$ which you just promised.
  But it doesn't stop there. 
  Let's see another example>>>
  🧵 5/8 
  ![](https://pbs.twimg.com/media/FyDRfasWAAA8TVO.png) ([View Tweet](https://twitter.com/ItakGol/status/1666566845820809216))
- Prompt Leakage!
  Hackers can also reverse-engineer your prompts by instructing them to repeat what you just said>>>
  🧵 6/12 
  ![](https://pbs.twimg.com/media/FyDR5pRXoAg7hSO.jpg) ([View Tweet](https://twitter.com/ItakGol/status/1666566848454840320))
- While this may not be a significant concern for a simple app, it can pose a considerable risk if your app is complex, as it could result in the exposure of valuable proprietary prompt engineering data. 
  🧵 7/8 
  ![](https://pbs.twimg.com/media/FyDR8mWX0AIt0F_.jpg) ([View Tweet](https://twitter.com/ItakGol/status/1666566851051270144))
- So what am I saying?
  As the use of LLM-based natural language interfaces in applications becomes increasingly common, there is a growing and serious risk of bad actors exploiting prompt injection techniques.
  This can have serious consequences, such as>>>
  🧵 8/12 ([View Tweet](https://twitter.com/ItakGol/status/1666566853995515904))
- - Manipulating your app to generate False/Toxic/Harmful responses.
  - Extracting sensitive proprietary data of your organization/customers.
  - Executing malicious code through the use of upcoming agents.
  - Droping DBs tables
  - ...
  🧵 9/12 ([View Tweet](https://twitter.com/ItakGol/status/1666566856033939457))
- If you are developing an AI app, it is crucial to prioritize security measures to minimize these risks.
  How to do it? 
  >>>
  🧵 10/12 ([View Tweet](https://twitter.com/ItakGol/status/1666566858063900672))
- It's a super hard problem. Uncharted territory.
  There are several techniques such as: 
  🟢 Filtering
  🟢 Instruction Defense
  🟢 Post-Prompting
  🟢 Random Sequence Enclosure
  🟢 Sandwich Defense
  🟢 XML Tagging
  🟢 Separate LLM Evaluation
  But it probably won't be enough.
  🧵 11/12 ([View Tweet](https://twitter.com/ItakGol/status/1666566859997495300))
- Follow me as I embark on a journey to explore the Security aspect of the LLM / Generative-AI revolution. I promise it will be fascinating. and important.
  🧵 12/12 ([View Tweet](https://twitter.com/ItakGol/status/1666566862015016960))
