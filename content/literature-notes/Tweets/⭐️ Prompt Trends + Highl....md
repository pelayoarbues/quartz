---
author: [[@LangChainAI on Twitter]]
title: "‚≠êÔ∏è Prompt Trends + Highl..."
date: 2023-10-19
tags: 
- tweets
- literature-note
---
![rw-book-cover](https://pbs.twimg.com/profile_images/1589007733226844160/i5-iIoSc.jpg)

## Metadata
- Author: [[@LangChainAI on Twitter]]
- Full Title: ‚≠êÔ∏è Prompt Trends + Highl...
- URL: https://twitter.com/LangChainAI/status/1714685906605822153

## Highlights
- ‚≠êÔ∏è Prompt Trends + Highlights ‚≠êÔ∏è
  We recently launched the LangChain Hub to support prompt sharing + workshopping.
  We collected hundreds of prompts across many use-cases. 
  Here, we distill major themes and highlight interesting examples.
  Blog:
  https://t.co/gX1DAcIdib 
  ![](https://pbs.twimg.com/media/F8u8Cw0bMAAFTeO.jpg) ([View Tweet](https://twitter.com/LangChainAI/status/1714685906605822153))
- Reasoning üß†
  Simple instructions ("think step by step") can improve many reasoning tasks. 
  Great thread from @_jasonwei w/ trade-offs: https://t.co/6IkIDOPtjH
  Recent @GoogleDeepMind work (img below) shows accuracy across many such instructions: 
  https://t.co/6DmVry2pSd 
  ![](https://pbs.twimg.com/media/F8u-kEnaIAAIm_7.jpg) ([View Tweet](https://twitter.com/LangChainAI/status/1714685908241502533))
- Writing ‚úçÔ∏è
  @mattshumer_ has shared some of our favorite prompts to improve your writing:
  https://t.co/TGrvSLcqXr
  https://t.co/7UXhzRDT28
  Also nice prompts for content generation (tests c/o @GregKamradt, threads c/o @HardKothari):
  https://t.co/BzWA1fp0Tp
  https://t.co/eZKAUOqAy6 ([View Tweet](https://twitter.com/LangChainAI/status/1714685910523289631))
- SQL üóÑÔ∏è
  @fpingham + others have done great work on text-to-SQL. 
  Giving LLM CREATE TABLE description and example rows (SELECT statement) improves SQL generation.
  Prompt: 
  https://t.co/8BHZ3oXEY6
  Paper: 
  https://t.co/2y8oRKUIA0 ([View Tweet](https://twitter.com/LangChainAI/status/1714685911995441537))
- Brainstorming üßë‚Äçüè´
  @mattshumer_ shared a great prompt using multiple user personas to ideate on business plans: 
  https://t.co/5PZSjSNjjy
  Also, prompt from NASA to emulate the strategies used by living things for design ideation:
  https://t.co/kGtgEx8Z5d
  https://t.co/qNSvLMjEUt ([View Tweet](https://twitter.com/LangChainAI/status/1714685913308209661))
- Extraction (1/2) üìí
  LLMs + fxn calling is powerful for extraction.
  See @jxnlco's great work on structured prompting for additional context:
  https://t.co/wDzb9J7FB2
  We've seen several prompts to support function calling, such as this:
  https://t.co/ntla148AIS ([View Tweet](https://twitter.com/LangChainAI/status/1714685914742710302))
- Extraction (2/2) üìí
  @yoheinakajima's Instagraph is a great example of extraction (knowledge graph triples):
  https://t.co/0VSALBDxrB
  Here's a prompt we have used for triple extraction:
  https://t.co/oNgWqhzVqQ 
  ![](https://pbs.twimg.com/media/F8vDRBKaEAA9S4x.jpg) ([View Tweet](https://twitter.com/LangChainAI/status/1714685916210667693))
- RAG üìì
  Retrieval augmented generation (RAG) is one of the most popular LLM applications:
  https://t.co/RP8WbtYdXE 
  We've seen prompt adaptation to support RAG w/ instructions for many open source LLMs (LLaMA2, Mistral, etc):
  https://t.co/9GDmzQ6gc4
  https://t.co/G5Ri3XZZqG 
  ![](https://pbs.twimg.com/media/F8vEJbqbwAAU4_S.jpg) ([View Tweet](https://twitter.com/LangChainAI/status/1714685918039494723))
- LLM Graders ‚úèÔ∏è
  Using LLMs as graders is a powerful idea in evaluation workflows.
  Lots of work in LangSmith has focused on this:
  https://t.co/3K7qm9Zf5n
  Some useful prompts:
  https://t.co/iw0glGL2Os
  https://t.co/mrllafONlo ([View Tweet](https://twitter.com/LangChainAI/status/1714685919905882401))
- Synthetic Data generation üìö
  Gathering training data to support LLM fine-tuning is a challenge.
  There's some great work from @AnthropicAI and others on this:
  https://t.co/sA0Hp7Ducq
  A few prompts to generate synthetic datasets:
  https://t.co/8nvXAXa9Vk
  https://t.co/MtQ5S8fN2U ([View Tweet](https://twitter.com/LangChainAI/status/1714685921382252917))
- Prompt Optimization ü§ñ
  LLMs can serve as translation modules between human instruction and LLM-optimized prompts.
  We've seen a few of these e.g., @midjourney: "Freddie Mercury performing at the 2023 San Francisco Pride Parade":
  https://t.co/FF2iiDSRHA
  https://t.co/QuW8G8iscR 
  ![](https://pbs.twimg.com/media/F8vGXKFasAA13Ti.jpg) ([View Tweet](https://twitter.com/LangChainAI/status/1714685922837762118))
- Code Understanding and Generation üë©‚Äçüíª
  Code analysis is one of the most popular LLM use-cases (e.g., Co-pilot, Code Interpreter, etc).
  We've seen many prompts for code review and generation:
  https://t.co/JQsfeXtWdo
  https://t.co/34ufua5ZAl ([View Tweet](https://twitter.com/LangChainAI/status/1714685924993605732))
- Summarization ‚è≥
  Content summarization is a powerful LLM use-case.
  Longer context LLMs, such as @AnthropicAI Claude2, can ingest 100+ pages for summarization:
  https://t.co/YKUbKIDwG0
  Techniques like chain of density offer a complimentary approach: 
  https://t.co/5fZF4ML4mL ([View Tweet](https://twitter.com/LangChainAI/status/1714685926318969237))
- Workshop and test any prompt in LangChain hub. 
  It offers a playground w/ a wide variety of LLMs: 
  + @thefireworksai: OSS models (e.g., LLaMA2)
  + OpenAI
  + Anthropic
  + Google PaLM
  + ... and more 
  ![](https://pbs.twimg.com/media/F8vIUTFaMAAByMU.jpg) 
  ![](https://pbs.twimg.com/media/F8vIvUlawAAI1Ep.jpg) ([View Tweet](https://twitter.com/LangChainAI/status/1714685927644422282))
