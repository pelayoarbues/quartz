---
author: [[@zhuohan123 on Twitter]]
title: "ðŸŒŸ Thrilled to Introduce..."
tags: 
- tweets
- literature-note
---
# ðŸŒŸ Thrilled to Introduce...

![rw-book-cover](https://pbs.twimg.com/profile_images/1230577035170340864/NRvpL0H8.jpg)

## Metadata
- Author: [[@zhuohan123 on Twitter]]
- Full Title: ðŸŒŸ Thrilled to Introduce...
- Category: #tweets
- URL: https://twitter.com/zhuohan123/status/1671234707206590464

## Highlights
- ðŸŒŸ Thrilled to introduce vLLM with @woosuk_k!
  ðŸš€ vLLM is an open-source LLM inference and serving library that accelerates HuggingFace Transformers by 24x and powers @lmsysorg Vicuna and Chatbot Arena.
  Github: https://t.co/kGwBXFjCqc
  Blog: https://t.co/M7g6pa8rHj ([View Tweet](https://twitter.com/zhuohan123/status/1671234707206590464))
- ðŸ”¥ The core of vLLM is PagedAttention, a novel attention algorithm that brings the classic idea of paging in OSâ€™s virtual memory to LLM serving. Without modifying the model, PagedAttention can batch 5x more sequences together, increasing GPU utilization and thus the throughput. https://t.co/J4ew3KsDRT ([View Tweet](https://twitter.com/zhuohan123/status/1671234709739941888))
- ðŸ¦¸ vLLM has been the unsung hero behind @lmsysorg Chatbot Arena and Vicuna Demo since April, handling peak traffic & serving popular models with high efficiency. It has cut the number of GPUs used at LMSYS by half while serving an average of 30K conversations daily. 
  ![](https://pbs.twimg.com/media/FzFqC3KaQAAUnBh.png) ([View Tweet](https://twitter.com/zhuohan123/status/1671234712436887552))
- This is a joint work of @woosuk_k, @zhuohan123, @zsy9509, @ying11231, @lm_zheng, @CodyHaoYu, @profjoeyg, @haozhangml, Ion Stoica.
  Check out our blog post and GitHub repo to start using vLLM now!
  Paper coming soon. ([View Tweet](https://twitter.com/zhuohan123/status/1671234715846848512))
