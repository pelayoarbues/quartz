---
author: [[@mathemagic1an on Twitter]]
title: "Clever (And Easy!) Trick..."
tags: 
- tweets
- literature-note
---
# Clever (And Easy!) Trick...

![rw-book-cover](https://pbs.twimg.com/profile_images/1607042017095258114/sSUQlvdW.jpg)

## Metadata
- Author: [[@mathemagic1an on Twitter]]
- Full Title: Clever (And Easy!) Trick...
- Category: #tweets
- URL: https://twitter.com/mathemagic1an/status/1615378778863157248

## Highlights
- Clever (and easy!) trick for better LLM context retrieval for those who haven't seen it:
  HyDE: Hypothetical Document Embeddings
  https://t.co/8EmTIfgIFW
  Take your query => create *hypothetical* answer => embed hypothetical answer => use this to search through doc embeddings
  1/ 
  ![](https://pbs.twimg.com/media/Fmr5CGpXEAAz1xA.jpg) ([View Tweet](https://twitter.com/mathemagic1an/status/1615378778863157248))
- This is great when you have a large number of documents that could serve as context (e.g. a full Google Drive or Slack history), yet the query content/embedding is semantically different than the relevant doc content.
  2/ ([View Tweet](https://twitter.com/mathemagic1an/status/1615378780557611010))
- You can implement this yourself on top of any black box LLM API and with your favorite vector search index
  OR
  `pip install langchain` ðŸš€ðŸš€
  @hwchase17 and crew are way ahead of the game.
  https://t.co/tFF7SsMaPf 
  ![](https://pbs.twimg.com/media/Fmr5_dTXwAAaa_Q.jpg) ([View Tweet](https://twitter.com/mathemagic1an/status/1615378782579470337))
---
author: [[@mathemagic1an on Twitter]]
title: "Clever (And Easy!) Trick..."
tags: 
- tweets
- literature-note
---
# Clever (And Easy!) Trick...

![rw-book-cover](https://pbs.twimg.com/profile_images/1607042017095258114/sSUQlvdW.jpg)

## Metadata
- Author: [[@mathemagic1an on Twitter]]
- Full Title: Clever (And Easy!) Trick...
- Category: #tweets
- URL: https://twitter.com/mathemagic1an/status/1615378778863157248

## Highlights
- Clever (and easy!) trick for better LLM context retrieval for those who haven't seen it:
  HyDE: Hypothetical Document Embeddings
  https://t.co/8EmTIfgIFW
  Take your query => create *hypothetical* answer => embed hypothetical answer => use this to search through doc embeddings
  1/ 
  ![](https://pbs.twimg.com/media/Fmr5CGpXEAAz1xA.jpg) ([View Tweet](https://twitter.com/mathemagic1an/status/1615378778863157248))
- This is great when you have a large number of documents that could serve as context (e.g. a full Google Drive or Slack history), yet the query content/embedding is semantically different than the relevant doc content.
  2/ ([View Tweet](https://twitter.com/mathemagic1an/status/1615378780557611010))
- You can implement this yourself on top of any black box LLM API and with your favorite vector search index
  OR
  `pip install langchain` ðŸš€ðŸš€
  @hwchase17 and crew are way ahead of the game.
  https://t.co/tFF7SsMaPf 
  ![](https://pbs.twimg.com/media/Fmr5_dTXwAAaa_Q.jpg) ([View Tweet](https://twitter.com/mathemagic1an/status/1615378782579470337))
---
author: [[@mathemagic1an on Twitter]]
title: "Clever (And Easy!) Trick..."
tags: 
- tweets
- literature-note
---
# Clever (And Easy!) Trick...

![rw-book-cover](https://pbs.twimg.com/profile_images/1607042017095258114/sSUQlvdW.jpg)

## Metadata
- Author: [[@mathemagic1an on Twitter]]
- Full Title: Clever (And Easy!) Trick...
- Category: #tweets
- URL: https://twitter.com/mathemagic1an/status/1615378778863157248

## Highlights
- Clever (and easy!) trick for better LLM context retrieval for those who haven't seen it:
  HyDE: Hypothetical Document Embeddings
  https://t.co/8EmTIfgIFW
  Take your query => create *hypothetical* answer => embed hypothetical answer => use this to search through doc embeddings
  1/ 
  ![](https://pbs.twimg.com/media/Fmr5CGpXEAAz1xA.jpg) ([View Tweet](https://twitter.com/mathemagic1an/status/1615378778863157248))
- This is great when you have a large number of documents that could serve as context (e.g. a full Google Drive or Slack history), yet the query content/embedding is semantically different than the relevant doc content.
  2/ ([View Tweet](https://twitter.com/mathemagic1an/status/1615378780557611010))
- You can implement this yourself on top of any black box LLM API and with your favorite vector search index
  OR
  `pip install langchain` ðŸš€ðŸš€
  @hwchase17 and crew are way ahead of the game.
  https://t.co/tFF7SsMaPf 
  ![](https://pbs.twimg.com/media/Fmr5_dTXwAAaa_Q.jpg) ([View Tweet](https://twitter.com/mathemagic1an/status/1615378782579470337))
---
author: [[@mathemagic1an on Twitter]]
title: "Clever (And Easy!) Trick..."
tags: 
- tweets
- literature-note
---
# Clever (And Easy!) Trick...

![rw-book-cover](https://pbs.twimg.com/profile_images/1607042017095258114/sSUQlvdW.jpg)

## Metadata
- Author: [[@mathemagic1an on Twitter]]
- Full Title: Clever (And Easy!) Trick...
- Category: #tweets
- URL: https://twitter.com/mathemagic1an/status/1615378778863157248

## Highlights
- Clever (and easy!) trick for better LLM context retrieval for those who haven't seen it:
  HyDE: Hypothetical Document Embeddings
  https://t.co/8EmTIfgIFW
  Take your query => create *hypothetical* answer => embed hypothetical answer => use this to search through doc embeddings
  1/ 
  ![](https://pbs.twimg.com/media/Fmr5CGpXEAAz1xA.jpg) ([View Tweet](https://twitter.com/mathemagic1an/status/1615378778863157248))
- This is great when you have a large number of documents that could serve as context (e.g. a full Google Drive or Slack history), yet the query content/embedding is semantically different than the relevant doc content.
  2/ ([View Tweet](https://twitter.com/mathemagic1an/status/1615378780557611010))
- You can implement this yourself on top of any black box LLM API and with your favorite vector search index
  OR
  `pip install langchain` ðŸš€ðŸš€
  @hwchase17 and crew are way ahead of the game.
  https://t.co/tFF7SsMaPf 
  ![](https://pbs.twimg.com/media/Fmr5_dTXwAAaa_Q.jpg) ([View Tweet](https://twitter.com/mathemagic1an/status/1615378782579470337))
